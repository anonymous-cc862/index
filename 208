您好，这是一个非常专业和有价值的问题。您不再是简单地想让预测值接近真实值，而是希望根据一个更复杂的、与业务成本直接相关的目标函数来优化模型。这是一个典型的\*\*自定义损失函数（Custom Loss Function）\*\*的应用场景。

LightGBM非常灵活，允许我们自定义目标函数，但它需要的不仅仅是损失值，还需要损失函数关于预测值的**一阶导数（梯度，Gradient）和二阶导数（海森值，Hessian）**。

下面我们分三步来解决这个问题：

1.  **将您的业务目标转化为一个数学损失函数**。
2.  **计算该损失函数的一阶和二阶导数**。
3.  **编写Python代码，在LightGBM中实现它**。

-----

### 1\. 将业务目标转化为损失函数

您的目标是双重的：

1.  **最小化“超额预测成本”**: `Cost = max(0, PM_stability_pred * SOD - EOD_true) * price_unadj`
2.  **最大化“预测名义价值”**: `Benefit = PM_stability_pred * SOD * price_unadj`

在机器学习中，我们通常将所有目标统一为最小化一个单一的损失函数。最大化一个值等同于最小化它的负值。因此，您的组合目标可以表示为最小化 `(Cost - Benefit)`。

为了在“降低成本”和“提高收益”之间进行权衡，我们引入一个超参数 `alpha` (取值在0到1之间)，来控制两者的相对重要性。

`Loss = alpha * Cost - (1 - alpha) * Benefit`

  * 当 `alpha` 接近1时，模型会更专注于降低超额预测的成本。
  * 当 `alpha` 接近0时，模型会更专注于最大化预测的名义价值。
  * 当 `alpha = 0.5`时，两者同等重要。

现在，我们用模型的预测值 `y_pred` (代表 `PM_stability_pred`) 和真实值 `y_true` (代表真实的 `PM_stability_true = EOD_true / SOD`) 来重写这个公式。

注意到 `EOD_true = y_true * SOD`，我们代入 `Cost` 的表达式中：
`Cost = max(0, y_pred * SOD - y_true * SOD) * price_unadj`
`Cost = max(0, y_pred - y_true) * SOD * price_unadj`

`Benefit` 的表达式为：
`Benefit = y_pred * SOD * price_unadj`

因此，最终的损失函数为：
`Loss(y_true, y_pred) = alpha * max(0, y_pred - y_true) * SOD * price_unadj - (1 - alpha) * y_pred * SOD * price_unadj`

为了方便，我们为每个样本 `i` 定义一个权重 `w_i = SOD_i * price_unadj_i`。
`Loss_i = w_i * [alpha * max(0, y_pred - y_true) - (1 - alpha) * y_pred]`

这就是我们要让LightGBM去最小化的目标。

-----

### 2\. 计算梯度（Gradient）和海森值（Hessian）

LightGBM需要知道损失函数 `Loss` 对预测值 `y_pred` 的一阶和二阶导数。

#### 一阶导数 (Gradient)

我们对 `Loss_i` 关于 `y_pred` 求导。这是一个分段函数，需要分情况讨论：

  * **情况1: `y_pred > y_true`** (超额预测)
    `Loss_i = w_i * [alpha * (y_pred - y_true) - (1 - alpha) * y_pred]`
    `grad_i = d(Loss_i) / d(y_pred) = w_i * [alpha - (1 - alpha)] = w_i * (2*alpha - 1)`

  * **情况2: `y_pred <= y_true`** (未超额预测或准确预测)
    `Loss_i = w_i * [0 - (1 - alpha) * y_pred]`
    `grad_i = d(Loss_i) / d(y_pred) = w_i * [ - (1 - alpha) ] = w_i * (alpha - 1)`

#### 二阶导数 (Hessian)

  * `hess_i = d²(Loss_i) / d(y_pred)²`
    我们的损失函数是**分段线性**的，这意味着它的梯度是分段常数。因此，二阶导数在所有地方都为0（在`y_pred = y_true`这个点不可导）。

在梯度提升算法中，Hessian为0会导致数值不稳定。这是一个常见问题（例如，在Quantile Loss或MAE中也会遇到）。标准做法是**用一个正常数来近似Hessian**，以保证训练的稳定性。最简单和最常见的选择是**将其设置为1**。这个常数作为叶节点权重计算中的分母，保证了算法的稳健性。

所以，我们设定 `hess_i = 1`。

**总结：**

  * **Gradient**: `grad = np.where(y_pred > y_true, w * (2*alpha - 1), w * (alpha - 1))`
  * **Hessian**: `hess = np.ones_like(y_true)`

-----

### 3\. Python代码实现

下面是如何在LightGBM中实现这个自定义目标函数。

```python
import lightgbm as lgb
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

# --- 模拟数据 ---
# 假设我们有一个处理好的DataFrame 'df'
# 它包含特征、y_true (PM_stability) 以及计算权重所需的 SOD 和 price_unadj
# (这里我们用随机数据模拟)
np.random.seed(42)
num_samples = 1000
df = pd.DataFrame({
    'feature1': np.random.rand(num_samples),
    'feature2': np.random.rand(num_samples),
    'SOD': np.random.randint(1000, 50000, size=num_samples),
    'price_unadj': np.random.uniform(5, 50, size=num_samples),
    'y_true': np.random.uniform(0.8, 1.2, size=num_samples) # 真实PM_stability
})
# 制造一些超额和不足预测的情况
df.loc[df.index % 5 == 0, 'y_true'] = 0.5
df.loc[df.index % 7 == 0, 'y_true'] = 0.0


# --- 自定义目标函数和评估函数 ---

def custom_objective_factory(alpha, sod, price_unadj):
    """
    使用一个工厂函数来创建目标函数，这样可以方便地传入 alpha 和其他数据。
    """
    # 将 Pandas Series 转换为 NumPy array 加速计算
    sod_arr = sod.to_numpy()
    price_unadj_arr = price_unadj.to_numpy()

    def custom_objective(y_true, y_pred):
        """
        这是实际传递给LightGBM的目标函数。
        """
        # 计算每个样本的权重 w
        w = sod_arr * price_unadj_arr
        
        # 计算梯度 (gradient)
        grad = np.where(y_pred > y_true, 
                        w * (2 * alpha - 1), 
                        w * (alpha - 1))
        
        # 计算海森值 (hessian)，用常数1来保证稳定性
        hess = np.ones_like(y_true)
        
        return grad, hess

    return custom_objective


def custom_eval_factory(alpha):
    """
    创建一个自定义的评估函数，用于在训练过程中监控我们关心的业务指标。
    """
    def custom_eval(y_true, y_pred):
        # 注意: 评估函数中无法直接获取SOD和price_unadj
        # 所以我们这里只计算一个近似的、无权重的版本，或在验证集上预先计算
        # 更优的做法是在训练循环外手动评估
        
        # 我们可以监控一个简化的指标，比如无权重的总损失
        cost = alpha * np.sum(np.maximum(0, y_pred - y_true))
        benefit = (1-alpha) * np.sum(y_pred)
        
        # LightGBM的feval需要返回一个列表，每个元素是 (metric_name, value, is_higher_better)
        return [('custom_loss', cost - benefit, False)]
        
    return custom_eval


# --- 模型训练 ---

# 1. 定义特征和目标
features = ['feature1', 'feature2']
target = 'y_true'

# 2. 划分数据
X_train, X_val, y_train, y_val = train_test_split(
    df[features], df[target], test_size=0.2, random_state=42
)
# 获取验证集对应的SOD和price_unadj
sod_val = df.loc[X_val.index, 'SOD']
price_unadj_val = df.loc[X_val.index, 'price_unadj']

# 3. 设置alpha值
# 这是一个需要根据业务需求调整的超参数
ALPHA = 0.7  # 假设我们更关心“超额预测成本”

# 4. 创建目标函数和评估函数实例
# 我们需要把训练集对应的SOD和price_unadj传入
sod_train = df.loc[X_train.index, 'SOD']
price_unadj_train = df.loc[X_train.index, 'price_unadj']
objective_func = custom_objective_factory(ALPHA, sod_train, price_unadj_train)
eval_func = custom_eval_factory(ALPHA)


# 5. 训练模型
train_data = lgb.Dataset(X_train, label=y_train)
val_data = lgb.Dataset(X_val, label=y_val)

params = {
    'objective': 'none',  # 关键：使用自定义目标时，必须设为'none'
    'metric': 'none',     # 关键：使用自定义评估指标时，也设为'none'
    'boosting_type': 'gbdt',
    'n_estimators': 1000,
    'learning_rate': 0.05,
    'verbose': -1
}

model = lgb.train(
    params,
    train_set=train_data,
    valid_sets=[val_data],
    callbacks=[lgb.early_stopping(100, verbose=True)],
    fobj=objective_func,
    feval=eval_func  # 注意：feval的权重问题，这里仅为示例
)

print("\n模型训练完成!")

# 6. 评估最终业务指标 (在验证集上)
y_pred_val = model.predict(X_val)

cost_val = np.sum(np.maximum(0, y_pred_val - y_val) * sod_val * price_unadj_val)
benefit_val = np.sum(y_pred_val * sod_val * price_unadj_val)

print(f"\n在验证集上的最终业务指标 (alpha={ALPHA}):")
print(f"总超额预测成本 (越小越好): {cost_val:,.2f}")
print(f"总预测名义价值 (越大越好): {benefit_val:,.2f}")
```

### 总结与建议

1.  **调整 `alpha`**：`alpha` 是您业务决策的核心。您需要通过实验或根据业务优先级来调整它。如果`alpha=0.7`意味着您认为“避免1元的超额成本”和“创造1元的预测价值”的重要性是7:3。
2.  **两阶段模型依然有效**：您之前提到的“仓位稳定 vs 仓位调整”的问题依然存在。一个更高级的方案是，先用一个分类器判断仓位是否会调整（`ADJUSTED`），然后**仅对预测为`ADJUSTED`的样本使用这个带有自定义损失函数的LightGBM模型**。这将让模型专注于最关键、最需要精细优化的样本上。
3.  **Hessian 的选择**：我们将Hessian设为常数1，这是最简单稳健的做法。在某些复杂情况下，可以尝试其他函数来近似Hessian，但这需要更多的数学推导和实验。对于您当前的目标函数，常数1是很好的起点。
